{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPQrNNyekFb4qMPiKbkhTfp"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5YW12FbZsJl8",
        "outputId": "fb9beb6d-6d87-40e4-90fd-f858a3632f0b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m97s\u001b[0m 61ms/step - accuracy: 0.3380 - loss: 1.8016 - val_accuracy: 0.5277 - val_loss: 1.3052 - learning_rate: 0.0010\n",
            "Epoch 2/10\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m92s\u001b[0m 59ms/step - accuracy: 0.4985 - loss: 1.3901 - val_accuracy: 0.5746 - val_loss: 1.1854 - learning_rate: 9.0000e-04\n",
            "Epoch 3/10\n",
            "\u001b[1m 775/1563\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m46s\u001b[0m 60ms/step - accuracy: 0.5455 - loss: 1.2695"
          ]
        }
      ],
      "source": [
        "#############改良箇所#########################\n",
        "#学習データに対してランダムな回転・ズーム・反転などを適用し、過学習防止のデータ拡張をしました。\n",
        "#エポックが進むにつれて学習率を動的に減少させ安定させました。\n",
        "#モデルが画像のどの部分を重視しているのかを表示しました。\n",
        "###################################################################\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import datasets, layers, models\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import cv2\n",
        "\n",
        "(train_images, train_labels), (test_images, test_labels) = datasets.cifar10.load_data()\n",
        "train_images, test_images = train_images / 255.0, test_images / 255.0\n",
        "\n",
        "class_names = ['airplane', 'automobile', 'bird', 'cat', 'deer',\n",
        "               'dog', 'frog', 'horse', 'ship', 'truck']\n",
        "\n",
        "data_augmentation = tf.keras.Sequential([\n",
        "    layers.RandomFlip(\"horizontal\"),\n",
        "    layers.RandomRotation(0.1),\n",
        "    layers.RandomZoom(0.1),\n",
        "])\n",
        "\n",
        "\n",
        "model = models.Sequential([\n",
        "    data_augmentation,\n",
        "    layers.Conv2D(32, (3, 3), activation='relu', input_shape=(32, 32, 3)),\n",
        "    layers.MaxPooling2D((2, 2)),\n",
        "    layers.Conv2D(64, (3, 3), activation='relu'),\n",
        "    layers.MaxPooling2D((2, 2)),\n",
        "    layers.Conv2D(64, (3, 3), activation='relu'),\n",
        "    layers.Flatten(),\n",
        "    layers.Dense(64, activation='relu'),\n",
        "    layers.Dense(10)\n",
        "])\n",
        "\n",
        "def lr_schedule(epoch, lr):\n",
        "    return lr * 0.9 if epoch > 0 else lr\n",
        "\n",
        "lr_callback = tf.keras.callbacks.LearningRateScheduler(lr_schedule)\n",
        "\n",
        "model.compile(optimizer='adam',\n",
        "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "history = model.fit(train_images, train_labels, epochs=10,\n",
        "                    validation_data=(test_images, test_labels),\n",
        "                    callbacks=[lr_callback])\n",
        "\n",
        "plt.plot(history.history['accuracy'], label='accuracy')\n",
        "plt.plot(history.history['val_accuracy'], label='val_accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.ylim([0, 1])\n",
        "plt.legend(loc='lower right')\n",
        "plt.show()\n",
        "\n",
        "test_loss, test_acc = model.evaluate(test_images, test_labels, verbose=2)\n",
        "print(f\"Test Accuracy: {test_acc:.4f}\")\n",
        "\n",
        "def grad_cam(image, model, class_index):\n",
        "    img_tensor = np.expand_dims(image, axis=0)\n",
        "\n",
        "    grad_model = tf.keras.models.Model([model.input],\n",
        "                                       [model.get_layer(index=-3).output, model.output])\n",
        "    with tf.GradientTape() as tape:\n",
        "        conv_outputs, predictions = grad_model(img_tensor)\n",
        "        loss = predictions[:, class_index]\n",
        "\n",
        "    grads = tape.gradient(loss, conv_outputs)[0]\n",
        "    pooled_grads = tf.reduce_mean(grads, axis=(0, 1, 2))\n",
        "    conv_outputs = conv_outputs[0]\n",
        "\n",
        "    heatmap = tf.reduce_sum(tf.multiply(pooled_grads, conv_outputs), axis=-1)\n",
        "\n",
        "    heatmap = np.maximum(heatmap, 0)\n",
        "    heatmap /= np.max(heatmap)\n",
        "    heatmap = cv2.resize(heatmap.numpy(), (32, 32))\n",
        "\n",
        "    heatmap = np.uint8(255 * heatmap)\n",
        "    heatmap = cv2.applyColorMap(heatmap, cv2.COLORMAP_JET)\n",
        "    superimposed_img = cv2.addWeighted(cv2.cvtColor(np.uint8(image * 255), cv2.COLOR_RGB2BGR), 0.6, heatmap, 0.4, 0)\n",
        "\n",
        "    return superimposed_img\n",
        "\n",
        "sample_image = test_images[0]\n",
        "predicted_label = np.argmax(model.predict(np.expand_dims(sample_image, axis=0)))\n",
        "grad_cam_image = grad_cam(sample_image, model, predicted_label)\n",
        "\n",
        "plt.figure(figsize=(10, 5))\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.imshow(sample_image)\n",
        "plt.axis('off')\n",
        "\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.imshow(grad_cam_image)\n",
        "plt.axis('off')\n",
        "\n",
        "plt.show()\n"
      ]
    }
  ]
}